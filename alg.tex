\documentclass{article}
\usepackage{fullpage}
\usepackage{mathpazo}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{color}

\newcommand*{\argmax}{\operatornamewithlimits{argmax}\limits}

\begin{document}

\begin{comment}

Parameters:
\[\begin{split}
  \alpha = 0.1 \leftarrow\ & q(s,a)\ \text{learning rate}\\
%  \beta = 0.1 \leftarrow\ & q(s,a,s')\ \text{learning rate}\\
  \gamma = 0.9 \leftarrow\ & \text{discount for infinite horizon}\\
  \tau = \alpha \leftarrow\ & \text{temperature diffusion coefficient}\\
  \delta = 0.995 \leftarrow\ & \text{temperature decay coefficient}\\
  \text{\it MaxTemp} = 50 \leftarrow\ &  \text{maximum temperature}\\
  \text{\it MinTemp} = 2 \leftarrow\ &  \text{minimum temperature}\\
  \theta \leftarrow\ & \text{lenience moderation factor}\\
%  \omega = 1 \leftarrow\ & \text{action selection moderation factor}\\
%  \upsilon = 1.0 \leftarrow\ & \text{temperature addition factor for lenience}\\
 % \zeta = 1.0 \leftarrow\ & \text{temperature addition factor for boltzman selection}\\
\end{split}\]

\end{comment}
Parameters:
\[
\begin{split}
\gamma = 0.9 \leftarrow\ & \text{reward discount for infinite horizon }\\
\tau = 0.9 \leftarrow\ & \text{demonstration signal discount for infinite horizon}\\
%\epsilon = 0 \leftarrow\ & \text{threshold for changing the priority of states}
\end{split}
\]
Initially:
\[\begin{split}
V(s) \leftarrow &\ 0 \text{ for all } s, \text{value of every state}\\
H(s) \leftarrow &\ 0 \text{ for all } s, \text{value of demonstration signal of every state}\\
Q(s,a) \leftarrow &\ 0 \text{ for all } s,a\\
N(s,a) \leftarrow &\ 0 \text{ for all } s,a\\
R(s,a) \leftarrow &\ 0  \text{ for all } s,a\\
N(s,a,s') \leftarrow &\ 0  \text{ for all } s,a,s'\\
D \leftarrow &\ \{\langle s_0,a_0,d_0\rangle , \langle s_1,a_1,d_1\rangle , \ldots ,\langle s_n,a_n,d_n\rangle \}\\
\text{RQueue} \leftarrow &\ \text{backup queue}\\
\text{DQueue} \leftarrow &\ \text{demonstration signal passing queue}
\end{split}\]

Repeat:\\

\begin{enumerate}

\item Select action \(a\) using the current policy $\pi$\\
\textcolor{red}{What do we want to use? $\epsilon$-greedy? What's the way that other PS paper using?}

\item The agent, in current state \(s\), performs action \(a\), receives reward \(r\), and transitions to new state \(s'\).

\item Update the transition model \(T(s,a,s')\) and reward model \(R(s,a)\)
\[
\begin{split}
N(s,a) \leftarrow &\ N(s,a) + 1\\
N(s,a,s') \leftarrow &\ N(s,a,s') + 1\\
R(s,a) \leftarrow &\ R(s,a) + r\\
\end{split}
\]

\item Do a one-step backup (\textcolor{red}{we may want to use SMALL BACKUP instead of full backup, since it's more efficient in computation time})\\
\[
\begin{split}
Q(s,a) \leftarrow &\ r + \gamma \Sigma_{s'}T(s,a,s')V(s')\\
V_{\text{old}}(s) \leftarrow &\ V(s)\\
V(s) \leftarrow &\ \max_{a'}Q(s,a')\\
\Delta_r \leftarrow &\ |V(s)-V_{\text{old}}(s)| \times \frac{2}{1+e^{-H(s)}}
\end{split}
\]

if state $s$ is on RQueue, set its priority to $\Delta_r$; otherwise, add it with priority $\Delta_r$

\item For a number of update cycles do\\
remove the first state $\bar{s}'$ from RQueue\\
for all $(\bar{s},\bar{a})$ pairs with $N(\bar{s},\bar{a},\bar{s}')>0$ do
\[
\begin{split}
\hat{r} \leftarrow &\ R(s,a)/N(s,a)\\
Q(\bar{s},\bar{a}) \leftarrow &\ \hat{r} +  \gamma \Sigma_{\bar{s}'}T(\bar{s},\bar{a},\bar{s}')V(\bar{s}')\\
V_{\text{old}}(\bar{s}) \leftarrow &\ V(\bar{s})\\
V(\bar{s}) \leftarrow &\ \max_{\bar{a}'}Q(\bar{s},\bar{a}')\\
\Delta_r \leftarrow &\ |V(\bar{s})-V_{\text{old}}(\bar{s})| \times \frac{2}{1+e^{-H(s)}}
\end{split}
\] 
if state $\bar{s}$ is on RQueue, set its priority to $\Delta_r$; otherwise, add it with priority $\Delta_r$

\item Do a one-step demonstration signal passing (\textcolor{red}{may want to switch order with step 5})\\
\[
\begin{split}
H_{\text{old}}(s') \leftarrow\ & H(s')\\
H(s') \leftarrow\ & \begin{cases}
    \max_{s,a} (d + \tau T(s,a,s') H(s))& \text{if \(\langle s,a \rangle\) is in $D$}\\
    \max_{s,a} (\tau T(s,a,s') H(s))& \text{otherwise}
  \end{cases}\\
  \Delta_d \leftarrow\ & |H(s')-H_{\text{old}}(s')|
  \end{split}
\]

if state $s'$ is on DQueue, set its priority to $\Delta_d$; otherwise, add it with priority $\Delta_d$
\item For a number of update cycles do\\
remove the first state $\bar{s}$ from DQueue\\
for all $(\bar{a},\bar{s}')$ pairs with $N(\bar{s},\bar{a},\bar{s}')>0$ do
\[
\begin{split}
H_{\text{old}}(\bar{s}') \leftarrow\ & H(\bar{s}')\\
H(\bar{s}') \leftarrow\ & \begin{cases}
    \max_{\bar{s},\bar{a}} (d + \tau  T(\bar{s},\bar{a},\bar{s}') H(\bar{s})& \text{if \(\langle \bar{s},\bar{a} \rangle\) is in $D$}\\
    \max_{\bar{s},\bar{a}} \tau  T(\bar{s},\bar{a},\bar{s}') H(\bar{s})& \text{otherwise}
  \end{cases}\\
  \Delta_d \leftarrow\ & |H(\bar{s}')-H_{\text{old}}(\bar{s}')|
  \end{split}
\] 
if state $\bar{s}$ is on DQueue, set its priority to $\Delta_d$; otherwise, add it with priority $\Delta_d$




	
\end{enumerate}

\end{document}
